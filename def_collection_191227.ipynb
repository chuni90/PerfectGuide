{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 칼럼별 unique value 확인\n",
    "* 칼럼별로 어떤 value를 가지고 있는 지\n",
    "* 그리고 각 비중(%) 어떻게 되는 지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count 파라미터는 unique value를 몇 개까지만 볼꺼냐?\n",
    "# 예) Sex는 남, 여 2개\n",
    "# 예2) 연령대는 10대, 20대, ~ , 60대 6개이므로 count가 5일때는 표시되지 않음\n",
    "\n",
    "def col_value_check(df,count) :\n",
    "    for i in df.columns :\n",
    "        print(\"{}'s Nunique: {}\\n\".format(i,df[i].nunique()))\n",
    "\n",
    "        if df[i].nunique() < count :\n",
    "            print(\"{:=^20}\".format(i))\n",
    "            print(round(df[i].value_counts() / df[i].value_counts().sum(),2))\n",
    "            print(\"{:=^20}\".format(\"=\"))\n",
    "    return\n",
    "col_value_check(test,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN Table\n",
    "* 적용 상황\n",
    "    - train, test의 각 칼럼별 NaN 값을 확인하고자 할 때\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 및 test에서 각각의 na 값을 DF형태로 반환\n",
    "\n",
    "def make_na_table(train, test):\n",
    "    train_na = train.isna().sum()\n",
    "    test_na = test.isna().sum()\n",
    "    na_table = pd.concat((train_na, test_na), join='outer', axis=1, sort=False, keys=('train','test'))\n",
    "    return na_table\n",
    "na_table = make_na_table(train,test)\n",
    "na_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* kaggle에서 발췌한 missing value df 만들기 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_data(df):\n",
    "    flag=df.isna().sum().any()\n",
    "    if flag==True:\n",
    "        total = df.isnull().sum()\n",
    "        percent = (df.isnull().sum())/(df.isnull().count()*100)\n",
    "        output = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "        data_type = []\n",
    "        # written by MJ Bahmani\n",
    "        for col in df.columns:\n",
    "            dtype = str(df[col].dtype)\n",
    "            data_type.append(dtype)\n",
    "        output['Types'] = data_type\n",
    "        return(np.transpose(output))\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique value Table\n",
    "* 적용 상황\n",
    "    - train, test의 각 칼럼별 unique value을 확인하고자 할 때\n",
    "    - columns이 index로 들어감\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unique_value_table(train, test) :\n",
    "    a = []\n",
    "    b = []\n",
    "\n",
    "    for x in range(0, len(train.columns)) :\n",
    "        a.append(train[train.columns[x]].nunique())\n",
    "        b.append(train.columns[x])\n",
    "    a1 = pd.Series(a, index=b)\n",
    "\n",
    "    c = []\n",
    "    d = []\n",
    "    for x in range(0, len(test.columns)) :\n",
    "        c.append(int(test[test.columns[x]].nunique()))\n",
    "        d.append(test.columns[x])\n",
    "\n",
    "    a2 = pd.Series(c, index=d)\n",
    "\n",
    "    unique_table = pd.concat([a1,a2], axis=1, sort=False, keys=['train', 'test'])\n",
    "    return unique_table\n",
    "unique_table = make_unique_value_table(train, test)\n",
    "unique_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IQR 로 Outlier 찾아내는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier 찾아내는 함수\n",
    "def get_outlier(df, col, weight=1.5) :\n",
    "    col = df[col]\n",
    "    quan_25 = np.percentile(col.values, 25)\n",
    "    quan_75 = np.percentile(col.values, 75)\n",
    "    \n",
    "    # IQR을 구하고, 1.5를 곱해서 최대/최소를 구함\n",
    "    iqr = quan_75 - quan_25\n",
    "    iqr_weight = iqr * weight\n",
    "    min_val = quan_25 - iqr_weight\n",
    "    max_val = quan_75 + iqr_weight\n",
    "    outlier_index = col[(col < min_val) | (col > max_val)].index\n",
    "    return outlier_index\n",
    "\n",
    "# 사용 예제\n",
    "\n",
    "for i in ride_col :\n",
    "    outlier_index = get_outlier(train2, i)\n",
    "    print(\"{}: {}\".format(i,train2.loc[outlier_index][i].shape[0]))\n",
    "print()\n",
    "for i in off_col :\n",
    "    outlier_index = get_outlier(train2, i)\n",
    "    print(\"{}: {}\".format(i,train2.loc[outlier_index][i].shape[0]))\n",
    "print()\n",
    "\n",
    "outlier_index = get_outlier(train2, '18~20_ride')\n",
    "print(\"{}: {}\".format('18~20_ride',train2.loc[outlier_index]['18~20_ride'].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이상치 제거 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 제거 함수\n",
    "\n",
    "def del_outlier(df, col_list) :\n",
    "    df_copy = df.copy()\n",
    "    for i in col_list :\n",
    "        outlier_index = get_outlier(df_copy, i)\n",
    "        df_copy.drop(outlier_index, axis=0, inplace=True)\n",
    "        print(i)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA 및 Randomforest 산출 함수\n",
    "* 적용 상황\n",
    "    - PCA를 통해 차원 축소가 필요한 데, 몇 개의 component가 필요한 지 모를 때\n",
    "    - components 수에 따른 R2(모델설명력)와 Randomforest의 score를 산출함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 최대개수에 맞게 components 수를 변화시키면서 설명력을 확인함\n",
    "# \n",
    "\n",
    "def pca_rcf(train_x, train_y, test_x, test_y) :\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    max_sum, max_com, max_result = 0.0, 0, 0.0\n",
    "    final_rcf = RandomForestClassifier()\n",
    "    \n",
    "    # components를 2~5개까지 테스트 해봄\n",
    "    for i in range(2, 5) :\n",
    "        pca = PCA(n_components=i)\n",
    "        pca_train_x = pca.fit_transform(train_x)\n",
    "        imp = []\n",
    "        \n",
    "        for p in pca.explained_variance_ratio_ :\n",
    "            imp.append(round(p,4))\n",
    "            \n",
    "        print(\"components:\",i,\"\\tTot:\",sum(imp))\n",
    "        rcf = RandomForestClassifier(n_estimators=1000, random_state=2442)\n",
    "        rcf.fit(train_x, train_y)\n",
    "        predicted = rcf.predict(test_x)\n",
    "        result = rcf.score(test_x, test_y)\n",
    "        print(\"\\tScore: {:.3f}\".format(result))\n",
    "        \n",
    "        if result > max_result :\n",
    "            max_result = result\n",
    "            final_rcf = rcf\n",
    "\n",
    "        if sum(imp) > max_sum :\n",
    "            max_sum = sum(imp)\n",
    "            max_com = i\n",
    "            \n",
    "    print(\"최종 >> 컴포넌트수: {}, R2: {:.3f}, 예측 정확도: {:.3f}\".format(max_com, max_sum, max_result))\n",
    "    # return 값으로 rcf 모델과 예측값을 반환함 (필요에 따라 수정혀)\n",
    "    return final_rcf, predicted\n",
    "\n",
    "rcf, predicted = pca_rcf(train_x, train_y, test_x, test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클러스터별 실루엣(클러스터링 점수) 확인\n",
    "* 아래 코드는 Kmeans로 클러스터링 한 후, 실루엣을 뽑아보는 것\n",
    "* 추후 클러스터링 알고리즘별로 제작하는 것도 방법일 듯\n",
    "* 한계\n",
    "    1. 실루엣 스코어 만으로 클러스터링의 정확도를 판단하는 것은 무리\n",
    "    2. 실제 분포(시각화)를 통해서 눈으로 보는 것도 중요함\n",
    "    3. 여러 클러스터링을 사용하여 최적의 군집개수(k)를 찾아보고 테스트 해보는 것을 추천함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_silhouette(cluster_lists, X_features): \n",
    "    \n",
    "    from sklearn.datasets import make_blobs\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    import math\n",
    "    \n",
    "    # 입력값으로 클러스터링 갯수들을 리스트로 받아서, 각 갯수별로 클러스터링을 적용하고 실루엣 개수를 구함\n",
    "    n_cols = len(cluster_lists)\n",
    "    \n",
    "    # plt.subplots()으로 리스트에 기재된 클러스터링 수만큼의 sub figures를 가지는 axs 생성 \n",
    "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "    \n",
    "    # 리스트에 기재된 클러스터링 갯수들을 차례로 iteration 수행하면서 실루엣 개수 시각화\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "        \n",
    "        # KMeans 클러스터링 수행하고, 실루엣 스코어와 개별 데이터의 실루엣 값 계산. \n",
    "        clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state=0)\n",
    "        cluster_labels = clusterer.fit_predict(X_features)\n",
    "        \n",
    "        sil_avg = silhouette_score(X_features, cluster_labels)\n",
    "        sil_values = silhouette_samples(X_features, cluster_labels)\n",
    "        \n",
    "        y_lower = 10\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\\n' \\\n",
    "                          'Silhouette Score :' + str(round(sil_avg,3)) )\n",
    "        axs[ind].set_xlabel(\"The silhouette coefficient values\")\n",
    "        axs[ind].set_ylabel(\"Cluster label\")\n",
    "        axs[ind].set_xlim([-0.1, 1])\n",
    "        axs[ind].set_ylim([0, len(X_features) + (n_cluster + 1) * 10])\n",
    "        axs[ind].set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        axs[ind].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        \n",
    "        # 클러스터링 갯수별로 fill_betweenx( )형태의 막대 그래프 표현. \n",
    "        for i in range(n_cluster):\n",
    "            ith_cluster_sil_values = sil_values[cluster_labels==i]\n",
    "            ith_cluster_sil_values.sort()\n",
    "            \n",
    "            size_cluster_i = ith_cluster_sil_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "            \n",
    "            color = cm.nipy_spectral(float(i) / n_cluster)\n",
    "            axs[ind].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \\\n",
    "                                facecolor=color, edgecolor=color, alpha=0.7)\n",
    "            axs[ind].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "            y_lower = y_upper + 10\n",
    "            \n",
    "        axs[ind].axvline(x=sil_avg, color=\"red\", linestyle=\"--\")\n",
    "visualize_silhouette([2,3,4,5,6], df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 성능 평가\n",
    "\n",
    "* classification 평가\n",
    "    * classification report\n",
    "    * roc_auc\n",
    "    * confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_train_eval(model, train_x,  test_x, train_y, test_y) :\n",
    "    from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "    \n",
    "    model.fit(train_x, train_y)\n",
    "    pred = model.predict(test_x)\n",
    "    print(\"==Confusion_matrix below==\\n\",confusion_matrix(test_y, pred))\n",
    "    print(classification_report(test_y, pred, digits=3))  # digit, 3자리 수까지만 표기\n",
    "    print()\n",
    "    print(\"{:>12}\\t{:.3f}\".format(\"ROC-AUC\",roc_auc_score(test_y, pred))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV - 교차 검증과 체적 하이퍼 파라미터 튜닝을 한 번에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSerchCV\n",
    "\n",
    "params = {\n",
    "    \"\" : [],\n",
    "    \"\" : []\n",
    "}\n",
    "\n",
    "grid_cv = GridSerchCV(model, param_grid = params, cv = 2, n_jobs = -1)\n",
    "grid_cv.fit(train_x, train_y)\n",
    "print(\"Best Params:\\n\", grid_cv.best_params_)\n",
    "print(\"Best predict score: {:.4f}\".format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전화번호, URL, PRICE 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone_number_filter(text):\n",
    "    re_pattern = r'\\d{2,3}[-\\.\\s]*\\d{3,4}[-\\.\\s]*\\d{4}(?!\\d)'\n",
    "    new_text = re.sub(re_pattern, 'tel', text)\n",
    "    re_pattern = r'\\(\\d{3}\\)\\s*\\d{4}[-\\.\\s]??\\d{4}'\n",
    "    new_text = re.sub(re_pattern, 'tel', new_text)\n",
    "    return new_text\n",
    "    \n",
    "    \n",
    "def url_filter(text):\n",
    "    re_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),|]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    new_text = re.sub(re_pattern, 'url', text)\n",
    "    return new_text\n",
    "\n",
    "\n",
    "def price_filter(text):\n",
    "    re_pattern = r'\\d{1,3}[,\\.]\\d{1,3}[만\\천]?\\s?[원]|\\d{1,5}[만\\천]?\\s?[원]'\n",
    "    text = re.sub(re_pattern, 'money', text)\n",
    "    re_pattern = r'[일/이/삼/사/오/육/칠/팔/구/십/백][만\\천]\\s?[원]'\n",
    "    text = re.sub(re_pattern, 'money', text)\n",
    "    re_pattern = r'(?!-)\\d{2,4}[0]{2,4}(?!년)(?!.)|\\d{1,3}[,/.]\\d{3}'\n",
    "    new_text = re.sub(re_pattern, 'money', text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 샘플링\n",
    "* Imbalanced Data Set에 적용\n",
    "* 모든 알고리즘을 적용한 것은 아님\n",
    "* [imblearn site](https://imbalanced-learn.readthedocs.io/en/stable/api.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_sampling in module __main__:\n",
      "\n",
      "make_sampling(X_train, y_train)\n",
      "    https://imbalanced-learn.readthedocs.io/en/stable/api.html\n",
      "    현재 5개만 추가된 상태\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_sampling(X_train, y_train) :\n",
    "    '''https://imbalanced-learn.readthedocs.io/en/stable/api.html\n",
    "    현재 5개만 추가된 상태'''\n",
    "    \n",
    "    from imblearn.under_sampling import EditedNearestNeighbours, NeighbourhoodCleaningRule, TomekLinks\n",
    "    from imblearn.over_sampling import SVMSMOTE\n",
    "    from imblearn.combine import SMOTEENN\n",
    "    from imblearn.metrics import sensitivity_score, specificity_score\n",
    "    \n",
    "    # Edited Nearest Neighbours (이웃 개수 및 kidn_sel ('all'/ 'mode') 둘 중 한개 택\n",
    "    x_enn, y_enn = EditedNearestNeighbours(sampling_strategy='auto', n_neighbors=3, \n",
    "                                           kind_sel='all', n_jobs=-1).fit_sample(X_train, y_train)\n",
    "    \n",
    "    # threshold_cleaing은 임계값\n",
    "    x_ncr, y_ncr = NeighbourhoodCleaningRule(sampling_strategy='auto', n_neighbors=3,\n",
    "                                             kind_sel='all', threshold_cleaning=0.5, n_jobs=-1).fit_sample(X_train, y_train)\n",
    "    \n",
    "    # SMOTE + ENN : only can use 'binary' \n",
    "    x_s_enn, y_s_enn = SMOTEENN(sampling_strategy='auto', random_state=None, n_jobs=-1).fit_sample(X_train, y_train)\n",
    "    \n",
    "    # Tomek's llnk\n",
    "    x_t, y_t = TomekLinks(n_jobs=-1).fit_sample(X_train, y_train)\n",
    "    \n",
    "    x_s_s, y_s_s = SVMSMOTE(n_jobs=-1).fit_sample(X_train, y_train)\n",
    "    \n",
    "    sampling_list = [x_enn, y_enn, x_ncr, y_ncr, x_s_enn, y_s_enn, x_t, y_t, x_s_s, y_s_s]\n",
    "    \n",
    "    return sampling_list\n",
    "\n",
    "help(make_sampling)\n",
    "\n",
    "###################\n",
    "\n",
    "def get_eval(y_test, pred) :\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score \n",
    "    \n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    acc = np.round(accuracy_score(y_test, pred),3)\n",
    "    pre = np.round(precision_score(y_test, pred),3)\n",
    "    recall = np.round(recall_score(y_test, pred),3)\n",
    "    f1 = np.round(f1_score(y_test, pred),3)\n",
    "    roc_auc = np.round(roc_auc_score(y_test, pred),3)\n",
    "\n",
    "    return cm, acc, pre, recall, f1, roc_auc\n",
    "######################\n",
    "\n",
    "def make_series(y_test, pred, index_name) :\n",
    "    cm, acc, pre, recall, f1, roc_auc = get_eval(y_test, pred)\n",
    "    score = pd.Series({'c_m':cm, 'acc': acc, 'precision':pre, 'recall':recall, 'f1':f1, 'roc_auc':roc_auc},\n",
    "                             name=index_name)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 샘플링된 것으로 모델에 넣는 것\n",
    "# 현재는 LGBM을 기본 모델로 채택\n",
    "\n",
    "def use_sampling(sampling_list, x_test, y_test) :\n",
    "    # sampling api 리스트\n",
    "    api = ['ENN', 'NCR', 'SMOTEENN', 'Tomek', 'SVMSMOTE']\n",
    "    \n",
    "    from lightgbm import LGBMClassifier\n",
    "\n",
    "    lgbm = LGBMClassifier(n_estimators=200, n_jobs=-1, random_state=1, learning_rate=0.1)\n",
    "    evals = [(x_test, y_test)]\n",
    "    score_df = pd.DataFrame(columns=['c_m','acc','precision','recall','f1','roc_auc'])\n",
    "    \n",
    "    for i in range(0,len(sampling_list),2) :\n",
    "        lgbm.fit(sampling_list[i], sampling_list[i+1], early_stopping_rounds=50, eval_metric=\"auc\", eval_set=evals, verbose=False)\n",
    "        pred = lgbm.predict(x_test)\n",
    "        \n",
    "        if i != 0 :\n",
    "            score = make_series(y_test, pred, api[int(i/2)])\n",
    "            score_df = score_df.append(score)\n",
    "        else :\n",
    "            score = make_series(y_test, pred, api[i])\n",
    "            score_df = score_df.append(score)\n",
    "    \n",
    "    return score_df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 실사용 예시 (x_train, y_train, x_test, y_test 모두 있어야함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_list = make_sampling(x_train, y_train)\n",
    "print(len(sampling_list))  # 모델별로 2개씩(x, y) 들어가므로 총 10개가 반환\n",
    "\n",
    "score_df = use_sampling(sampling_list, x_test, y_test)\n",
    "score_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
